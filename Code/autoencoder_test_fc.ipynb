{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "\n",
    "sep_data = th.load('../datasets/sep_states1.pt')\n",
    "\n",
    "ent_data = th.load('../datasets/ent_states1.pt')\n",
    "\n",
    "sep_data_pair = th.stack((sep_data.real, sep_data.imag), dim=-1)\n",
    "ent_data_pair = th.stack((ent_data.real, ent_data.imag), dim=-1)\n",
    "\n",
    "sep_data_pair.shape, ent_data_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "sep_train, sep_test = train_test_split(sep_data_pair, test_size=0.3)\n",
    "ent_train, ent_test = train_test_split(ent_data_pair, test_size=0.3)\n",
    "\n",
    "sep_train.shape, sep_test.shape, ent_train.shape, ent_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "ent_train_loader = DataLoader(ent_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "ent_test_loader = DataLoader(ent_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "sep_train_loader = DataLoader(sep_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "sep_test_loader = DataLoader(sep_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import train and test dataset, scale them and convert them to data loaders\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "MNIST_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform= transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0, 1)]),\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = MNIST_dataset.data, MNIST_dataset.targets\n",
    "\n",
    "mask = labels == 6\n",
    "\n",
    "MNIST_6 = data[mask].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = MNIST_6,\n",
    "                          batch_size = BATCH_SIZE,\n",
    "                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(train_loader)).numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "\n",
    "def custom_loss(x, x_hat, mean, logvar):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD = -0.5 * th.sum(1 + logvar - mean * mean - logvar.exp())\n",
    "    \n",
    "    return reproduction_loss + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_fc(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VAE_fc, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        \n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_size[1], hidden_size[0])\n",
    "        self.fc4 = nn.Linear(hidden_size[0], input_size)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \n",
    "        # print(\"flatten\", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        # print(\"fc1\", x.shape)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        # print(\"fc2\", x.shape)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x):\n",
    "        x = self.fc3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        return nn.Sigmoid()(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(\"input\", x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(\"flatten\", x.shape)\n",
    "        encoded = self.encode(x)\n",
    "        \n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_accuracy(logit, target):\n",
    "    corrects = (th.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects / target.size(0)\n",
    "    return accuracy.item()\n",
    "\n",
    "\n",
    "def get_test_stats(model, criterion, test_loader, device):\n",
    "    test_acc, test_loss = 0.0, 0.0\n",
    "    for _, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        _, decoded = model(data)\n",
    "        test_loss += criterion(data, decoded).item()\n",
    "        test_acc += get_batch_accuracy(data, decoded)\n",
    "        return test_loss, test_acc\n",
    "\n",
    "def train_model(model, train_loader, epochs, optimizer, criterion, device):\n",
    "    _trained_model = model.to(device)\n",
    "    _trained_model.train()\n",
    "    _train_loss = []\n",
    "    for _ in range(epochs):\n",
    "        _total_loss = 0.0\n",
    "        for _, _data in enumerate(train_loader):\n",
    "            _data = _data.to(device)\n",
    "            _, _decoded = _trained_model(_data)\n",
    "            _loss = criterion(_data.flatten(start_dim=1), _decoded)\n",
    "            optimizer.zero_grad()\n",
    "            _loss.backward()\n",
    "            optimizer.step()\n",
    "            _total_loss += _loss.item() * data.size(0)\n",
    "            \n",
    "        _train_loss.append(_total_loss / len(train_loader.dataset))\n",
    "        \n",
    "        # print('Epoch: {}, Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "    return _train_loss, _trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_fc(input_size=4 * 2, hidden_size=[32, 16])\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loss, model = train_model(model=model,\n",
    "                    train_loader=ent_train_loader,\n",
    "                    epochs=100,\n",
    "                    optimizer=optimizer,\n",
    "                    criterion=nn.MSELoss(),\n",
    "                    device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(train_loss)), train_loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, result = model(ent_train)\n",
    "\n",
    "ent_data_reconsructed = result.view(-1, 4, 2)\n",
    "\n",
    "ent_data_reconsructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_fc(input_size=28 * 28, hidden_size=[14 * 28, 14 * 14])\n",
    "\n",
    "\n",
    "model = train_model(model=model,\n",
    "                    train_loader=train_loader,\n",
    "                    epochs=5,\n",
    "                    optimizer=optimizer,\n",
    "                    criterion=nn.MSELoss(),\n",
    "                    device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reconstructed_data = model(MNIST_6)\n",
    "\n",
    "reconstructed_data = reconstructed_data.view(-1, 28, 28).detach().numpy()\n",
    "reconstructed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(reconstructed_data))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(reconstructed_data))\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_data_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_dataset = TensorDataset(sep_data_pair[:, :, 0], sep_data_pair[:, :, 1])\n",
    "dataloader = DataLoader(sep_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Variational Autoencoder (VAE) class\n",
    "class QuantumVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(QuantumVAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        # self.encoder = nn.Sequential(\n",
    "        #     nn.Linear(input_dim, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(128, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, latent_dim * 2)  # Multiply by 2 for mean and log-variance\n",
    "        # )\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, latent_dim * 2)\n",
    "        \n",
    "        \n",
    "\n",
    "        # # Decoder\n",
    "        # self.decoder = nn.Sequential(\n",
    "        #     nn.Linear(latent_dim, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(128, input_dim),\n",
    "        #     nn.Tanh()  # Assuming quantum states are represented by complex vectors\n",
    "        # )\n",
    "        \n",
    "        self.fc4 = nn.Linear(latent_dim, 64)\n",
    "        self.fc5 = nn.Linear(64, 128)\n",
    "        self.fc6 = nn.Linear(128, input_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        # print(\"Init\", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        # print(\"fc1\", x.shape)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        # print(\"fc2\", x.shape)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        # print(\"fc3\", x.shape)\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.fc4(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc5(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc6(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        return x\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = th.exp(0.5 * logvar)\n",
    "        eps = th.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x_real, x_imag):\n",
    "        # Concatenate real and imaginary parts\n",
    "        # print(\"real\", x_real.shape)\n",
    "        # print(\"imag\", x_imag.shape)\n",
    "        x = th.cat([x_real, x_imag], dim=1)\n",
    "        # print(\"concat\", x.shape)\n",
    "\n",
    "        # Encode\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        # Split into mean and log-variance\n",
    "        mu, logvar = th.chunk(encoded, 2, dim=1)\n",
    "\n",
    "        # Reparameterize\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # Decode\n",
    "        decoded = self.decoder(z)\n",
    "\n",
    "        # Split the decoded output into real and imaginary parts\n",
    "        decoded_real, decoded_imag = th.chunk(decoded, 2, dim=1)\n",
    "\n",
    "        return decoded_real, decoded_imag, mu, logvar\n",
    "\n",
    "# Example usage\n",
    "input_dim = 81 * 2  # Assuming complex vectors of length 81\n",
    "latent_dim = 16  # Adjust as needed\n",
    "\n",
    "# Instantiate the QuantumVAE model\n",
    "quantum_vae = QuantumVAE(input_dim, latent_dim)\n",
    "\n",
    "\n",
    "for x_real, x_imag in dataloader:\n",
    "    reconstructions_real, reconstructions_imag, mu, logvar = quantum_vae(x_real, x_imag)\n",
    "    print(reconstructions_real.shape, reconstructions_imag.shape, mu.shape, logvar.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4025.6628\n",
      "Epoch [2/10], Loss: 0.7752\n",
      "Epoch [3/10], Loss: 0.3411\n",
      "Epoch [4/10], Loss: 0.1947\n",
      "Epoch [5/10], Loss: 0.1365\n",
      "Epoch [6/10], Loss: 0.1090\n",
      "Epoch [7/10], Loss: 0.0916\n",
      "Epoch [8/10], Loss: 0.0872\n",
      "Epoch [9/10], Loss: 0.0967\n",
      "Epoch [10/10], Loss: 0.1282\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "quantum_vae = QuantumVAE(input_dim, latent_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(quantum_vae.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (you need to provide your dataset and DataLoader)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for data_real, data_imag in dataloader:  # Assuming you have separate real and imaginary parts in your dataset\n",
    "        # Forward pass\n",
    "        reconstructions_real, reconstructions_imag, mu, logvar = quantum_vae(data_real, data_imag)\n",
    "\n",
    "        # Concatenate real and imaginary parts for the loss calculation\n",
    "        inputs_real = data_real\n",
    "        inputs_imag = data_imag\n",
    "        reconstructions = th.cat([reconstructions_real, reconstructions_imag], dim=1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(reconstructions, th.cat([inputs_real, inputs_imag], dim=1)) + 0.5 * th.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n",
    "        train_loss += loss.item() * data_real.size(0)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss at the end of each epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 2, 81])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_real, decoded_imag, _, _ = quantum_vae(sep_data_pair[:, :, 0], sep_data_pair[:, :, 1])\n",
    "\n",
    "decoded = th.stack([decoded_real, decoded_imag], dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
